{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01086f8-7ae4-4247-a229-9a198f211c53",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">BERT для решения задачи multi-label классификации текстов.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4281a-7261-4468-9f93-0190c11722c8",
   "metadata": {},
   "source": [
    "<center> <h2>1. Импорт данных и приведение таргета к нужному виду. </h2> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fccd41-c838-4947-aeda-77e0824b3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b325a12d-8a07-4941-8fed-40f9ec24b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv(\"../data/processed/train/text_train_df.csv\", index_col=0)\n",
    "X_val_df = pd.read_csv(\"../data/processed/val/text_val_df.csv\", index_col=0)\n",
    "\n",
    "y_train_df = pd.read_csv(\"../data/processed/train/target_train_df.csv\", index_col=0)\n",
    "y_val_df = pd.read_csv(\"../data/processed/val/target_val_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a09238f-5e09-47d9-9236-f4590591649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропуски, которые возникли из-за наличия отзывов без текста\n",
    "X_train_df = X_train_df.fillna('')\n",
    "X_val_df = X_val_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ccc6b7-acc3-474e-8897-9215d9892301",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [f\"trend_id_res{i}\" for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096113d0-bb9c-4f7e-9395-f9af638858e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_list(row) -> list:\n",
    "    target_list = []\n",
    "    for target in target_cols:\n",
    "        target_list.append(row[target])\n",
    "    return target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b87e4a-049b-4872-a715-181d849a78de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         target_list\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            target_list\n",
       "4161  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4162  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
       "4163  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4164  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "4165  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_df = pd.DataFrame(y_train_df.apply(make_target_list, axis=1), columns=['target_list'])\n",
    "y_val_df = pd.DataFrame(y_val_df.apply(make_target_list, axis=1), columns=['target_list'])\n",
    "display(y_train_df.head())\n",
    "display(y_val_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48f5cb-b932-41ba-aa07-65f90a6663dc",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3ed9b-a1fb-4417-a79f-d419efc8a19e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e1c09-624d-4dfb-bee8-0bdfd459cdb3",
   "metadata": {},
   "source": [
    "<center><h2> 2. Приведение данных к torch формату для скармливанию модельке.</h2><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d735d8c7-d0ef-4a1b-b50e-76035d00b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5905eb6c-16ac-4249-913c-c452a5c8fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b42a0a54-cc45-47d9-a32a-c62210ba9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"Класс для преобразования датасета к нужному формату\"\"\"\n",
    "    def __init__(self, X, y, tokenizer, max_len=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentences = X['text'].tolist()\n",
    "        self.labels = y['target_list'].tolist()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.sentences[idx]\n",
    "        target_list = self.labels[idx]\n",
    "        # токенизируем\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text=text, \n",
    "            add_special_tokens=True, # добавление спец-токенов, отвечающих за \"начало предложения\" [CLS] и \"конец предложения\" [SEP]\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            return_token_type_ids=False, # это для задачи вопросно-ответной системы, т.е. не для нас\n",
    "            return_attention_mask=True, \n",
    "            return_tensors='pt' # формат выдачи токенизатора, в нашем случае - torch тензор\n",
    "        )\n",
    "\n",
    "        # то что мы запихнем в модель\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(), # это наши цифровые токены (т.е. для токена 'привет' будет какое-нибудь '105')\n",
    "            'attention_mask': inputs['attention_mask'].flatten(), # это наши маски\n",
    "            'labels': torch.tensor(target_list, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a018082a-8d55-40fc-9489-92ad2eaf640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbed73c1-48b2-4452-93d1-ac4e1f0b4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d52a7d-1b75-4cb9-88de-9d309164a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Маленький берт, легче, быстрее.\n",
    "rubert_tiny_model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\", return_dict=False)\n",
    "rubert_tiny_tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "\n",
    "# Берт покрупнее\n",
    "rubert_model = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased', return_dict=False)\n",
    "rubert_tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48b1fa68-c941-453e-aa31-39f857c49028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(X_train_df, y_train_df, rubert_tokenizer)\n",
    "val_dataset = TextDataset(X_val_df, y_val_df, rubert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48d7c2c7-2793-4d82-888f-c0fe4a880f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f24ec-7737-45b6-86a2-cabbbb182847",
   "metadata": {},
   "source": [
    "<center> <h2>3. Создадим класс нейронки для решения задачи</h2> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8b4a617-774e-4fe0-a58a-be93d8bd643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMultiLabel(torch.nn.Module):\n",
    "    def __init__(self, bert, n_classes):\n",
    "        super(BertMultiLabel, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.fc = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        _, output = self.bert(ids, attention_mask=mask)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8af990e-0da2-4083-aa33-42430f1bff27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertMultiLabel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model = BertMultiLabel(rubert_model, 50)\n",
    "custom_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ff3d485-bddc-44e5-b49c-4582d762746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params =  custom_model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a570a5-7a41-4f04-ada3-53ab20d3fcf2",
   "metadata": {},
   "source": [
    "<center><h2>4. Обучение модели</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0df4ecfa-88f2-4418-bc77-3df6838fbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_val(model, train_data_loader, val_data_loader, loss_fn, optimizer, device, num_epochs, save_path=\"../models/rubert\"):\n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        train_epoch_loss = []\n",
    "        eval_epoch_loss = []\n",
    "        \n",
    "        print(\"Эпоха номер: \", t)\n",
    "\n",
    "        # Обучение модели на текущей эпохе\n",
    "        print(\"Обучение началось...\")\n",
    "        batch_counter = 0\n",
    "        all_batches_count = len(train_data_loader)\n",
    "        \n",
    "        model.train()\n",
    "        for train_data in tqdm(train_data_loader):\n",
    "            \n",
    "            batch_counter += 1\n",
    "            if batch_counter % 50 == 0:\n",
    "                print(f\"Прошло {batch_counter} батчей из {all_batches_count}\")\n",
    "            \n",
    "            input_ids = train_data['input_ids'].to(device) # токены\n",
    "            attention_mask = train_data['attention_mask'].to(device) # маски\n",
    "            labels = train_data['labels'].to(device) # класс\n",
    "\n",
    "            outputs = model(input_ids, attention_mask) # результат модели\n",
    "            #_, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels) # считаем потерю\n",
    "            train_epoch_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            # Выполним подсчёт новых градиентов\n",
    "            loss.backward()\n",
    "            # Выполним шаг градиентного спуска\n",
    "            optimizer.step()\n",
    "            # Обнулим сохраненные у оптимизатора значения градиентов\n",
    "            # перед следующим шагом обучения\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Оценка модели на валидационных данных после обучения на текущей эпохе\n",
    "        print(\"Оцениваем модель после эпохи обучения...\")\n",
    "        model.eval()\n",
    "        for val_data in tqdm(val_data_loader):\n",
    "            input_ids = val_data['input_ids'].to(device) # токены\n",
    "            attention_mask = val_data['attention_mask'].to(device) # маски\n",
    "            labels = val_data['labels'].to(device) # класс\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask) # результат модели\n",
    "            \n",
    "                loss = loss_fn(outputs, labels) # считаем потерю\n",
    "                eval_epoch_loss.append(loss.item())\n",
    "\n",
    "        # Выведем результаты прошедшей эпохи обучения\n",
    "        print(\"Train loss: \", np.mean(train_epoch_loss))\n",
    "        print(\"Eval loss: \", np.mean(eval_epoch_loss))\n",
    "        \n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabad85-2f24-4aa3-a16d-64b00ff6ffb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a80ff9dcf044f05927c4d879943807c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха номер:  0\n",
      "Обучение началось...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128aede762f14d07bf4199a437a2effe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прошло 50 батчей из 261\n",
      "Прошло 100 батчей из 261\n",
      "Прошло 150 батчей из 261\n",
      "Прошло 200 батчей из 261\n",
      "Прошло 250 батчей из 261\n",
      "Оцениваем модель после эпохи обучения...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de976596a6994051ab40dc8b73a609d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2957573650097938\n",
      "Eval loss:  0.15051439147571039\n",
      "Эпоха номер:  1\n",
      "Обучение началось...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8463e7fb1f6941b78ca390f7cce1d08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прошло 50 батчей из 261\n",
      "Прошло 100 батчей из 261\n",
      "Прошло 150 батчей из 261\n",
      "Прошло 200 батчей из 261\n",
      "Прошло 250 батчей из 261\n",
      "Оцениваем модель после эпохи обучения...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1c919959a94d7f9954b4b538ad6db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.13254223829599177\n",
      "Eval loss:  0.11933782259965765\n",
      "Эпоха номер:  2\n",
      "Обучение началось...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545da843b9e24628b1afff121fa9df87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прошло 50 батчей из 261\n"
     ]
    }
   ],
   "source": [
    "trained_custom_model = train_val(custom_model, train_data_loader, val_data_loader, loss_fn, optimizer, device, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ddcc63-1e89-49da-950b-26c4424c8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_custom_model.state_dict(), \"../models/rubert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8da1ba-9f00-4c58-a388-cef7740251ad",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cad1a8-d12f-412b-96c5-21d1c5f2aab4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01980985-332e-40fb-b293-ce190425bd98",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc4b5e-7561-4eaa-9035-6be32c0b2ca0",
   "metadata": {},
   "source": [
    "<center><h2>5. Считаем accuracy на валидационной части.</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a83a9-ad4e-4fd5-b1fb-3fd9decb95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25da377-3ac0-4f2f-95e7-5286f7782d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(model, X_val, y_val, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        text_dataset = TextDataset(X_val, y_val, tokenizer)\n",
    "        data_loader = DataLoader(text_dataset, batch_size=len(text_dataset), shuffle=False)\n",
    "        data = next(iter(data_loader))\n",
    "\n",
    "        input_ids = data['input_ids'].to(device) # токены\n",
    "        attention_mask = data['attention_mask'].to(device) # маски\n",
    "        targets = data['labels']\n",
    "\n",
    "        output = model(input_ids, attention_mask)\n",
    "\n",
    "        predictions = (output.detach().numpy() >= 0.5).astype(int)\n",
    "        y_true = targets.detach().numpy().astype(int)\n",
    "\n",
    "    return accuracy_score(y_true, predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923a9cf-624f-4015-b6ec-a7e93574d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy(trained_custom_model, X_val_df, y_val_df, rubert_tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
